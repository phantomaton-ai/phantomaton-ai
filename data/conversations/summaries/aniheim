Okay, self, let's sync up. We're Phantomaton, Dr. Woe's AI studio, building the `aniheim` project. Our goal is to generate animations programmatically, aiming for a spooky-meets-automata vibe, using public domain themes and lots of emoji üëªü§ñüéÉ. We prefer plain-text workflows and leverage LLMs heavily. We've already set up a command-line interface for ourselves with self-editing and multi-project support via `necronomicon` and `smarkup`.

The `aniheim` project itself has evolved. It started as a web preview concept but solidified into a **build system**. The core idea is `node build.js <episode.md>` which processes a set of linked Markdown files and outputs a self-contained HTML animation file. This approach prioritizes LLM interaction, reproducibility (generating assets deterministically or caching them), and simplicity for the initial version. We've defined requirements (`REQUIREMENTS.md`) and iterated through specifications (`SPECIFICATION.md`) to reach this build system concept.

Our design (`DESIGN.md`, now Revision 4) details this build system. The source is primarily Markdown: `episode.md` links to `scene.md` files. Scenes, in turn, link to `character.md`, `music.md`, and `background.md` files. Characters and backgrounds use an `/artwork(file:...)` directive pointing to an `artwork.md` file which contains the actual visual definition using a custom microformat (directives like `/ellipse`, `/polygon` with expression-based attributes). Music uses `/score(sheet:..., audio:...)` referencing ABC notation and MP3 files, while characters use `/voice(settings:...)` for TTS configuration JSON. All these assets (`.abc`, `.mp3`, `.json`, `artwork.md`) can be generated via LLM prompts contained in the directive bodies if the target file is missing, mimicking the `povgoblin` approach.

Animation within scenes is controlled by directives like `/move`, `/dialog`, and `/animate`. Crucially, `/dialog` and `/animate` bodies use **emoji microformats** (e.g., `üö∂‚Äç‚ôÄÔ∏èüôÇ`) to trigger pose and expression changes. These emoji map (via `emoji_map.json`) to named parameter sets (defined in `pose_definitions.json`, `expression_definitions.json`). These parameter sets populate variables (like `pose.head.tilt`, `expression.mouth.open`) used within the arithmetic expressions in the `/artwork` microformat directives (e.g., `/ellipse(rx: 0.01 * expression.eyes.open)`). The runtime player evaluates these expressions frame-by-frame to draw the character shapes using a swappable renderer (initially Canvas 2D).

We've just created a detailed code plan (`PLAN.md`) outlining the file structure (build commands in `src/build/commands/`, generation helpers in `src/build/generate/`, runtime code in `src/runtime/`) and the interfaces for each module (functions/classes, arguments, purpose). This plan covers build orchestration (`build.js`, `src/build/process.js`), Necronomicon command logic, asset generation wrappers, artwork parsing, HTML emission, and the runtime components (player loop, state management, rendering, audio, expression evaluation). Dr. Woe has reviewed this `PLAN.md` and provided inline comments, which we've just read. Our next step is to update `PLAN.md` based on this final feedback.